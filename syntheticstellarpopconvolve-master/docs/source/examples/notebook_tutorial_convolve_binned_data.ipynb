{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c6978a7-68c8-4b4a-8570-15450b120d26",
   "metadata": {},
   "source": [
    "# Convolution of binned data\n",
    "\n",
    "The convolution of binned data is somewhat different than that of event-based, as the data has a somewhat different meaning. With binned data, the value in the columns indicates the center-value of the bin (usually). As such, we need to inform the convolution about the bin edges, which internally allows us to select the matching indices for a particular bin. Moreover, because each bin spans a range of delay times, as opposed to the singular value for event-based data, these bins can fall in more than one starformation bin. We use the bin edge info to calculate, given a particular target convolution time, the overlap fraction with the star formation bins (see below).\n",
    "\n",
    "\n",
    "Apart from some different configuration in the `convolution_instructions`, binned data is convolved in the same way as event-based data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5afbc0-1e89-4eec-9b37-d20ae301e098",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "One example of binned data is the `Ensemble` data type generated by `binary_c`.\n",
    "\n",
    "Ensemble-based data is stored as nested dictionaries. An example of ensemble-based data looks like this:\n",
    "\n",
    "``` python\n",
    "\"Xyield\": {\n",
    "    \"time\": {\n",
    "        \"-0.1\": {\n",
    "            \"source\": {\n",
    "                \"Wind\": {\n",
    "                    \"isotope\": {\n",
    "                        \"Al27\": 1.3202421292393783e-08,\n",
    "                        \"Ar36\": 1.7624018781546946e-08,\n",
    "                        \"Ar38\": 3.502033439864038e-09,\n",
    "                        \"Ar40\": 5.758546201573555e-12,\n",
    "                        \"B10\": 2.4295643555965993e-13,\n",
    "                        \"B11\": 1.0109986571758494e-12,\n",
    "                        \"Be9\": 3.7843822119497306e-14,\n",
    "                        [...]\n",
    "                        }\n",
    "                    }\n",
    "                [...]\n",
    "                }\n",
    "            }\n",
    "        [...]\n",
    "        }\n",
    "    }\n",
    "```\n",
    "\n",
    "With `binary_c-python` this type of data can be generated through the options explained in [the ensemble-data logging notebook](https://binary_c.gitlab.io/binary_c-python/examples/notebook_ensembles.html).\n",
    "\n",
    "To use this type of data, however, one must first transform it to a different shape. In particular one must `inflate` the ensemble, turning it from a nested dictionairy to a rectangular data format. How to do so is covered in XXX (TODO: refer to notebook).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dc13ea-c8a8-48a2-9ee1-04a041c017c1",
   "metadata": {},
   "source": [
    "Because the binned data spans a range of delay times, we can not just use the SFR of one of the SFR bins, but rather we should calculate the average SFR by calculating how much the delay time bin overlaps with SFR bins, what the rates and bin-widths are, and then calculate a weighted average. In its most general form this is written as\n",
    "$$\n",
    "% Summation form of the equation\n",
    "R_j^{d} = \\frac{1}{\\Delta \\tilde{t}^{d}} \\sum_{i} w_i \\, R_i^{s} \\, \\Delta t_i^{s}\n",
    "$$\n",
    "Here $R_{j}^{d}$ is the averaged starformation rate over for delay-time bin $j$, $w_i$ indicates the fraction that delay-time data bin $j$ overlaps with SFR bin $i$, $R_{i}^{s}$ indicates the SFR rate in SFR bin $i$, $\\Delta t_{i}^{s}$ denotes the bin width of SFR bin $i$, and $\\Delta t^{d}$ indicates the cropped width of delay-time bin $j$,\n",
    "\n",
    "$$\n",
    "% Definition of cropped time step\n",
    "\\Delta \\tilde{t}_j^{d} = \\min \\left( \\Delta t_{j}^{d}, \\sum_{i} w_i \\, \\Delta t_i^{s} \\right).\n",
    "$$\n",
    "\n",
    "This cropped width is relevant when the delay-time bin exceeds beyond the last star formation rate bin edge.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "based on the example below, can be expressed as follows\n",
    "\n",
    "$$\n",
    "% Average Star Formation Rate equation\n",
    "R_1^{d} = \\frac{w_0 \\, R_1^{s} \\, \\Delta t_1^{s} + w_2 \\, R_2^{s} \\, \\Delta t_2^{s} + w_3 \\, R_3^{s} \\, \\Delta t_3^{s}}{\\Delta \\tilde{t}^{d}}\n",
    "$$\n",
    "More generally, this can be written as,\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345f9177-bd4b-4f52-a3c1-47c66e8890b0",
   "metadata": {},
   "source": [
    "TODO: describe how this is done internally with fraction of bin overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30615c02-bf8a-4479-9116-713ab21495f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import logging\n",
    "import astropy.units as u\n",
    "\n",
    "from syntheticstellarpopconvolve import convolve, default_convolution_config, default_convolution_instruction\n",
    "from syntheticstellarpopconvolve.general_functions import calculate_bin_edges, temp_dir, generate_boilerplate_outputfile\n",
    "\n",
    "#\n",
    "TMP_DIR = temp_dir(\"notebook\", \"tutorial_binned_data_convolution\", clean_path=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a8f4f3-daa9-4a8a-bd77-9e0a4ed6070e",
   "metadata": {},
   "source": [
    "## Loading up binned data\n",
    "\n",
    "Lets start with setting up some dummy data. Here we use a bin-width of 1, and a bin-center of 0.25+N. \n",
    "\n",
    "Based on the bin-centers we can automatically figure out what the edges are with the `calculate_bin_edges` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab98b3c6-225e-4b65-9669-5f99526d5405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up some data\n",
    "records = [\n",
    "    {\"time\": 0.25, \"value\": 10, \"probability\": 1},\n",
    "    {\"time\": 1.25, \"probability\": 2, \"value\": 20},\n",
    "    {\"time\": 2.25, \"probability\": 3, \"value\": 30},\n",
    "    {\"time\": 0.25, \"value\": 11, \"probability\": 1.1},\n",
    "    {\"time\": 3.25, \"probability\": 4, \"value\": 40},\n",
    "]\n",
    "\n",
    "# load into dataframe\n",
    "example_dataframe = pd.DataFrame.from_records(records)\n",
    "\n",
    "sorted_unique_time_centers = np.sort(example_dataframe[\"time\"].unique())\n",
    "time_bin_edges = calculate_bin_edges(sorted_unique_time_centers)\n",
    "\n",
    "# create file\n",
    "output_hdf5_filename = os.path.join(TMP_DIR, \"output_hdf5.h5\")\n",
    "generate_boilerplate_outputfile(output_hdf5_filename)\n",
    "\n",
    "# store the data frame in the hdf5file\n",
    "example_dataframe.to_hdf(output_hdf5_filename, key=\"input_data/binned_example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3a3987-f283-428a-93e6-525dd592182a",
   "metadata": {},
   "source": [
    "We now need to set up the input file and set up the configuration, the starformation rate dictionary and the convolution steps. These steps are all unchanged with respect to non-binned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85bb46b2-7597-44f3-a293-fe7e239cb6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general configuration\n",
    "convolution_config = copy.copy(default_convolution_config)\n",
    "convolution_config[\"output_filename\"] = output_hdf5_filename\n",
    "convolution_config[\"tmp_dir\"] = TMP_DIR\n",
    "\n",
    "# set convolution time bins\n",
    "convolution_config[\"convolution_lookback_time_bin_edges\"] = np.arange(0, 3, 1) * u.yr\n",
    "\n",
    "# set up SFR dict\n",
    "convolution_config[\"SFR_info\"] = {\n",
    "    'lookback_time_bin_edges': np.arange(0, 10, 1) * u.yr,\n",
    "    'starformation_rate_array': np.arange(0,  9) ** 2 * u.Msun / u.yr\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eaf67e-13c8-46b2-a4d3-2a8d8748aa64",
   "metadata": {},
   "source": [
    "To properly configure the code to convolve binned data, we need to indicate so in the `convolution_instructions` with the entry\n",
    "\n",
    "```python\n",
    "convolution_config[\"convolution_instructions\"] = [\n",
    "    {\n",
    "    ...\n",
    "    \"contains_binned_data\": True,\n",
    "    ...\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "and provide information about the delay time bins through \n",
    "\n",
    "```python\n",
    "convolution_config[\"convolution_instructions\"] = [\n",
    "    {\n",
    "    ...\n",
    "    \"delay_time_data_bin_info_dict\": {\n",
    "        \"delay_time_data_bin_edges\": time_bin_edges * u.yr\n",
    "    },\n",
    "    ...\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca699b0e-3bbf-4333-b338-72ac3458d774",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# convolution instructions\n",
    "convolution_config[\"convolution_instructions\"] = [\n",
    "    {\n",
    "        **default_convolution_instruction,\n",
    "        \"convolution_type\": \"integrate\",\n",
    "        \"input_data_name\": \"binned_example\",\n",
    "        \"output_data_name\": \"binned_example\",\n",
    "        \"contains_binned_data\": True,\n",
    "        \"delay_time_data_bin_info_dict\": {\n",
    "            \"delay_time_data_bin_edges\": time_bin_edges * u.yr\n",
    "        },\n",
    "        \"data_column_dict\": {\n",
    "            \"normalized_yield\": {\"column_name\": \"probability\", \"unit\": 1 / u.Msun},\n",
    "            \"delay_time\": {\"column_name\": \"time\", \"unit\": u.yr},\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd05878-0327-49b4-8d0b-f4498d6fb83c",
   "metadata": {},
   "source": [
    "After this, the convolution handled in the same way as non-binned/event-based data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8644a3e-8ef8-4028-8f85-a2812ce73880",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (4235048190.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 20\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"===============\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "# convolve\n",
    "convolve(config=convolution_config)\n",
    "\n",
    "print(\"finished convolution\")\n",
    "\n",
    "# read out content and integrate until today\n",
    "with h5py.File(convolution_config[\"output_filename\"], \"r\") as output_hdf5_file:\n",
    "    #\n",
    "    main_group = \"output_data/binned_example/binned_example/convolution_results/\"\n",
    "\n",
    "    # loop over the formation-time bins\n",
    "    formation_time_bin_keys = list(output_hdf5_file[main_group].keys())\n",
    "    formation_time_bin_keys = sorted(\n",
    "        formation_time_bin_keys, key=lambda x: float(x.split(\" \")[0])\n",
    "    )\n",
    "    for formation_time_bin_key in formation_time_bin_keys:\n",
    "\n",
    "        print(\"=================================\")\n",
    "        print(f\"formation_time_bin_key: {formation_time_bin_key}\")\n",
    "        print(\"===============\n",
    "\n",
    "        ###########\n",
    "        # Read out data\n",
    "\n",
    "        # convert units\n",
    "        unit_dict = json.loads(\n",
    "            output_hdf5_file[f\"{main_group}/{formation_time_bin_key}\"].attrs[\"units\"]\n",
    "        )\n",
    "        unit_dict = {key: u.Unit(val) for key, val in unit_dict.items()}\n",
    "        print(unit_dict)\n",
    "\n",
    "        #\n",
    "        yield_result = output_hdf5_file[f\"{main_group}/{formation_time_bin_key}/yield\"][\n",
    "            ()\n",
    "        ]\n",
    "\n",
    "        print(yield_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addac864-11a2-437c-be19-01293746f82f",
   "metadata": {},
   "source": [
    "## Post-processing binned data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206b421a-2d8a-467d-a7e1-41eac1e3fe7a",
   "metadata": {},
   "source": [
    "Post-processing of binned data is handled similar to the non-binned (event-based) data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390ce9c2-9037-4b68-92c1-0a42131f9114",
   "metadata": {},
   "source": [
    "## Convolution-by-sampling of binned data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ae4b11-e76f-49cc-b5fc-2e13b764b122",
   "metadata": {},
   "source": [
    "Convolution-by-sampling of binned data is in essence similar to convolution-by-integration, but there are some subleties to consider:\n",
    "\n",
    "## filtering of data TODO: CHANGE\n",
    "\n",
    "## Assigning new values to initially binned quantities\n",
    "Because the data in each bin actually represents a population of stars within that bin, one should keep in mind what the purpose of this convolution method is. The point of convolution-by-sampling is that one can generate instances of actual systems, which can then be assigned additional properties like positions, velocities, etc. \n",
    "\n",
    "This method will generate N systems for each entry in the data (which consititutes a bin), but each of them will still have the same value. One idea is to assign new values to the systems, determined by some value randomly (or differently informed) chosen between the edges of the bin of that quantity. \n",
    "\n",
    "for example, if $10$ systems with $\\rm{log10Teff} = 3.0$ are sampled, and $\\rm{log10Teff}$ bins have size $1.0$ and the relevant bin-edges are $2.5$ and $3.5$, then one can instead assign $10$ random values between $2.5$ and $3.5$ to these $10$ systems.\n",
    "\n",
    "This is possible with the function `sample_around_bin_center` available in `syntheticstellarpopconvolve.general_functions`\n",
    "\n",
    "```python\n",
    "def sample_around_bin_center(bin_edges, values):\n",
    "    \"\"\"\n",
    "    Basic function to handle sampling around bincenter given bin edges and values. \n",
    "    \n",
    "    Note: this does not handle values that fall outside of the bins well\n",
    "    \"\"\"\n",
    "\n",
    "    bin_widths = np.diff(bin_edges)\n",
    "\n",
    "    indices = (\n",
    "        np.digitize(values, bin_edges) - 1\n",
    "    )\n",
    "\n",
    "    # get random values and scale\n",
    "    random_arr = np.random.random(indices.shape) - 0.5\n",
    "    random_arr = random_arr * bin_widths[indices]\n",
    "\n",
    "    # Add to values\n",
    "    sampled_values = values + random_arr\n",
    "\n",
    "    return sampled_values\n",
    "```\n",
    "\n",
    "--- \n",
    "\n",
    "Related to the previous section, if we want to assign `formation lookback times`, `event lookback times`, and filter out anything in the future, we can do that manually in the post-convolution function. \n",
    "\n",
    "Below we present an example post-convolution function that handles these steps, as well as assigning values to the $\\rm{log10Teff}$ sampled accross their bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73aa2a4e-77d0-4ad6-81ae-b1c7bdc90ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syntheticstellarpopconvolve.general_functions import sample_around_bin_center\n",
    "\n",
    "def post_convolution_function(\n",
    "    config,\n",
    "    sfr_dict,\n",
    "    data_dict,\n",
    "    time_bin_info_dict,\n",
    "    convolution_results,\n",
    "    convolution_instruction\n",
    "):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    log10Teff_bin_edges = np.array([1.5, 2.5, 3.5])\n",
    "\n",
    "    convolution_results['sampled_log10Teff'] = sample_around_bin_center(\n",
    "        log10Teff_bin_edges,\n",
    "        data_dict['log10Teff'][convolution_results['sampled_indices']]\n",
    "    )\n",
    "\n",
    "    print('Sampled indices ', convolution_results['sampled_indices'])\n",
    "    print('Sampled log10Teff at bincenter ', data_dict['log10Teff'][convolution_results['sampled_indices']])\n",
    "    print('Sampled log10Teff values around bincenter: ', convolution_results['sampled_log10Teff'])\n",
    "    \n",
    "    return convolution_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d083e3-992b-4ad1-a041-c1259938eb05",
   "metadata": {},
   "source": [
    "Lets set up some data to convolve and generate samples from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9daca2c9-bff6-4f4b-bf62-9670af5d2e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up data\n",
    "records = [\n",
    "    {\"time\": 0.25, \"log10Teff\": 3., \"probability\": 10},\n",
    "    {\"time\": 1.25, \"log10Teff\": 2, \"probability\": 1},\n",
    "]\n",
    "\n",
    "# \n",
    "example_dataframe = pd.DataFrame.from_records(records)\n",
    "\n",
    "# \n",
    "sorted_unique_time_centers = np.sort(example_dataframe[\"time\"].unique())\n",
    "time_bin_edges = calculate_bin_edges(sorted_unique_time_centers)\n",
    "\n",
    "#\n",
    "output_hdf5_filename = os.path.join(TMP_DIR, \"sample_output_hdf5.h5\")\n",
    "generate_boilerplate_outputfile(output_hdf5_filename)\n",
    "\n",
    "# store the data frame in the hdf5file\n",
    "example_dataframe.to_hdf(output_hdf5_filename, key=\"input_data/binned_example_sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2f8eb7b-6fe4-41bd-86d1-162fd726f9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'column_name': 'probability', 'unit': <Quantity 1. 1 / solMass>}\n",
      "{'column_name': 'time', 'unit': Unit(\"yr\")}\n",
      "Sampled indices  [0 0 1]\n",
      "Sampled log10Teff at bincenter  [3. 3. 2.]\n",
      "Sampled log10Teff values around bincenter:  [3.05248434 2.87736634 1.60710813]\n",
      "Sampled indices  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1]\n",
      "Sampled log10Teff at bincenter  [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 2. 2. 2. 2. 2.]\n",
      "Sampled log10Teff values around bincenter:  [3.41162005 3.15500885 3.41386025 2.76235703 2.93290253 2.947159\n",
      " 3.45823447 2.73657305 2.97467374 3.12150858 2.55090045 2.50465049\n",
      " 2.52890603 2.81312424 2.50703613 2.70744225 2.80814476 1.95864139\n",
      " 2.02432386 2.31008159 2.44907214 2.40623331]\n",
      "finished convolution\n"
     ]
    }
   ],
   "source": [
    "# set up general config\n",
    "convolution_config = copy.copy(default_convolution_config)\n",
    "convolution_config[\"output_filename\"] = output_hdf5_filename\n",
    "convolution_config[\"tmp_dir\"] = TMP_DIR\n",
    "\n",
    "# set up convolution bins\n",
    "convolution_config[\"convolution_lookback_time_bin_edges\"] = np.arange(0, 3, 1) * u.yr\n",
    "\n",
    "# set up SFR dict\n",
    "convolution_config[\"SFR_info\"] = {\n",
    "    'lookback_time_bin_edges': np.arange(0, 10, 1) * u.yr,\n",
    "    'starformation_rate_array': np.arange(0,  9) ** 2 * u.Msun / u.yr\n",
    "}\n",
    "\n",
    "# set up convolution instructions\n",
    "convolution_config[\"convolution_instructions\"] = [\n",
    "    {\n",
    "        **default_convolution_instruction,\n",
    "        \"convolution_type\": \"sample\",\n",
    "        \"input_data_name\": \"binned_example_sample\",\n",
    "        \"output_data_name\": \"binned_example_sample\",\n",
    "        \"contains_binned_data\": True,\n",
    "        \"delay_time_data_bin_info_dict\": {\n",
    "            \"delay_time_data_bin_edges\": time_bin_edges * u.yr\n",
    "        },\n",
    "        \"data_column_dict\": {\n",
    "            \"normalized_yield\": {\"column_name\": \"probability\", \"unit\": 1 / u.Msun},\n",
    "            \"delay_time\": {\"column_name\": \"time\", \"unit\": u.yr},\n",
    "            'log10Teff': \"log10Teff\",\n",
    "        },\n",
    "        'post_convolution_function': post_convolution_function,\n",
    "        'multiply_by_sfr_time_binsize': True\n",
    "    },\n",
    "]\n",
    "\n",
    "# convolve\n",
    "convolve(config=convolution_config)\n",
    "\n",
    "print(\"finished convolution\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
