{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d456961a-c0ef-4097-89c5-897fbbddf573",
   "metadata": {},
   "source": [
    "# Example use-case: LISA UCB convolution of double white-dwarf binaries at current-day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b9e5bb-dc0c-4a56-869f-7c18c4237645",
   "metadata": {},
   "source": [
    "This example fleshes out the steps required to estimate the population of observable double white dwarf systems in the LISA band. Relevant studies are: https://arxiv.org/abs/2405.20484\n",
    "\n",
    "Several ingredients are necessary here:\n",
    "- population-synthesis results that contain white-dwarfs\n",
    "- a Milky-Way galaxy star formation rate history model\n",
    "- a method to evolve double white-dwarf under the influence of gravitational wave radiation.\n",
    "\n",
    "Convolution-by-sampling was developed especially for this project, as we want to 'generate' double white dwarf systems at a certain lookback time, and evolve them (through gravitational-wave radiation) to the present day.\n",
    "\n",
    "The convolution broadly is done as follows:\n",
    "- In a given lookback-time bin we calculate the total mass formed into stars\n",
    "- We use that to generate double white dwarf systems (using mass_formed * yield-per-mass-formed) \n",
    "- We assign a birth time to these systems (with values bound by the edges of the lookback time bin)\n",
    "- We 'evolve' these systems up to the current day under the influence of gravitational-wave radiation. We make use of Legwork ([Wagg et al 2021](https://ui.adsabs.harvard.edu/abs/2022ApJS..260...52W/abstract)) in this example.\n",
    "- Filter out certain systems (in particular those that, at current-day, are not in the LISA waveband)\n",
    "- Calculate detection probabilities for the rest based on their position (either randomly assigned or motivated by a spatially-defined SFH) in the Milkyway and their system properties.\n",
    "- Use this information to predict observable populations of DWD systems\n",
    "\n",
    "In the following notebook I will show how to set up all the necessary pieces for this script and how to put them together. We will start some general imports like usual, then continue with setting up the `sfr_dict`, then design the post convolution function, and then combine everything and run the convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbf9968-58b2-4812-8423-ec9c43859c74",
   "metadata": {},
   "source": [
    "Lets start with setting up some form of star formation rate for the milkyway. There are many estimates and descriptions of increasing complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5c25927-cdba-4f25-b527-bcdd8e4e6283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23799/3006275116.py:10: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "import astropy.units as u\n",
    "import legwork as lw\n",
    "import numpy as np\n",
    "import astropy.constants as const\n",
    "import pandas as pd\n",
    "import pkg_resources\n",
    "import h5py\n",
    "\n",
    "from syntheticstellarpopconvolve import convolve, default_convolution_config, default_convolution_instruction\n",
    "from syntheticstellarpopconvolve.general_functions import temp_dir, generate_boilerplate_outputfile\n",
    "from syntheticstellarpopconvolve.convolution_by_sampling import (\n",
    "    select_dict_entries_with_new_indices,\n",
    ")\n",
    "\n",
    "from syntheticstellarpopconvolve.usecase_notebook_utils.usecase_lisa_utils import get_mass_norm, sample_distances_simple, get_period, sample_distances_interpolated\n",
    "\n",
    "TMP_DIR = temp_dir(\"code\", \"convolve_stochastically\", clean_path=True)\n",
    "\n",
    "# The flag below allows the user to run this notebook without the full data or starformation rate. \n",
    "FULL_VERSION = os.getenv(\"EXAMPLE_USECASE_UCB_VERSION\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e17b91d-5137-4814-b8fe-14ae65a483a8",
   "metadata": {},
   "source": [
    "Next step is to load some data. In this case we have loaded some data expressed in the T0 bincodex format, and sourced from SeBa simulations, which are Monte-Carlo based (opposed to grid-based) simulations. We want to select double white-dwarf systems only, and provide a `normalized_yield` to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed9fd9d1-e0cb-450e-ae0b-2c2603160b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_filename = os.getenv('EXAMPLE_DATA_USECASE_UCB_FILENAME') if FULL_VERSION else None\n",
    "example_usecase_UCB_events_filename = data_filename if data_filename is not None else pkg_resources.resource_filename(\n",
    "    \"syntheticstellarpopconvolve\",\n",
    "    \"example_data/example_BinCodex_dwd.h5\"\n",
    ")\n",
    "example_usecase_UCB_events_data = pd.read_hdf(example_usecase_UCB_events_filename,  key='T0')\n",
    "\n",
    "## \n",
    "# Determine the normalized_yield and select only systems that are double white-dwarfs\n",
    "\n",
    "# get mass normalisation\n",
    "mass_normalisation_fiducial = get_mass_norm(IC_model=\"fiducial\", binary_fraction=0.5)\n",
    "\n",
    "# set normalised yield\n",
    "example_usecase_UCB_events_data[\"normalized_yield\"] = 1 / mass_normalisation_fiducial\n",
    "# Query the dataset to select the formation of the WDs\n",
    "\n",
    "# check if things start with some number. It's easier to turn them into strings for this.\n",
    "example_usecase_UCB_events_data[\"str_event\"] = example_usecase_UCB_events_data[\"event\"].astype(str)\n",
    "example_usecase_UCB_events_data[\"str_type1\"] = example_usecase_UCB_events_data[\"type1\"].astype(str)\n",
    "example_usecase_UCB_events_data[\"str_type2\"] = example_usecase_UCB_events_data[\"type2\"].astype(str)\n",
    "\n",
    "# lets query the type-changing events. Any type-change will do\n",
    "wd_binaries = example_usecase_UCB_events_data.query(\"str_event.str.startswith('1')\")\n",
    "\n",
    "# The type should change to a WD-type (and the other should already be one)\n",
    "wd_binaries = wd_binaries.query(\"str_type1.str.startswith('2')\")\n",
    "wd_binaries = wd_binaries.query(\"str_type2.str.startswith('2')\")\n",
    "\n",
    "# Lets delete the string versions of the columns again\n",
    "wd_binaries = wd_binaries.drop(columns=[\"str_event\", \"str_type1\", \"str_type2\"])\n",
    "\n",
    "# lets also delete the original dataframe\n",
    "del example_usecase_UCB_events_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57007964-f27c-4678-b3ad-a7c808c300a2",
   "metadata": {},
   "source": [
    "Lets now set up some form of star formation rate for the Milkyway. There are many estimates and descriptions of increasing complexity, but for simplicity lets take a constant star formation that within 10Gyr will have formed a mass equivalent to the stellar mass of the Milky way. We will ignore metallicity here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80b1a55f-6c0a-499c-b879-b6eaf814c89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_dict = {}\n",
    "scale = 1e-1\n",
    "\n",
    "# Set up the lookback time bins\n",
    "if FULL_VERSION:\n",
    "    sfr_dict[\"lookback_time_bin_edges\"] = (np.arange(0, 10, 0.1) * u.Gyr).to(u.yr)\n",
    "else:\n",
    "    sfr_dict[\"lookback_time_bin_edges\"] = (np.arange(0., 10., 1) * u.Gyr).to(u.yr)\n",
    "\n",
    "#\n",
    "sfr_dict[\"starformation_rate_array\"] = (6 * u.Msun / u.yr) *  np.ones(sfr_dict[\"lookback_time_bin_edges\"].shape[0] - 1)\n",
    "\n",
    "if not FULL_VERSION:\n",
    "    sfr_dict[\"starformation_rate_array\"] *= scale\n",
    "# sfr_dict[\"starformation_rate_array\"] *= scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40e13bf-86a4-44cc-97be-d53f02f18912",
   "metadata": {},
   "source": [
    "With the starformation information now configured, we can design the actual machinery of this calculation: the post-convolution step.\n",
    "\n",
    "Convolution by sampling 'generates' systems, and returns indices to those systems that allows us to link back to system properties. It also provides formation times that we can use.\n",
    "\n",
    "The idea in this routine will be to:\n",
    "- Use the 'generated' system (indices)\n",
    "- Calculate the the time difference between current day (lookback time = 0) and the lookback time where the event occurred (lookback time = formation time + delay time). Filter out events that occur in the future.\n",
    "- Use this time to 'evolve' the double white dwarf system forward in time under the influence of gravitational wave radiation. (we use Legwork).\n",
    "- Filter out systems that fall outside of the LISA waveband.\n",
    "\n",
    "This is what we will handle within the post-convolution. We will thus store every system that falls within the LISA waveband at current day. We will handle the processing of detectability in the next step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8906135-3f09-4c04-a697-48311bab9d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import functools\n",
    "import logging \n",
    "\n",
    "from syntheticstellarpopconvolve.usecase_notebook_utils.usecase_lisa_utils import precompute_radial_cdf, sample_distances_interpolated\n",
    "\n",
    "\n",
    "Hr = 4  # Radial scale length\n",
    "inverse_cdf = precompute_radial_cdf(Hr)\n",
    "bound_sample_distances_interpolated = functools.partial(\n",
    "    sample_distances_interpolated,\n",
    "    inverse_cdf=inverse_cdf\n",
    ")\n",
    "\n",
    "\n",
    "def post_convolution_function(\n",
    "    config, sfr_dict, data_dict, time_bin_info_dict, convolution_results, convolution_instruction\n",
    "):\n",
    "    \"\"\"\n",
    "    Post-convolution function to handle integrating the systems forward in time and finding those that end up in the LISA waveband.\n",
    "\n",
    "    using local_indices to select everything and using Alexey's distance sampler to handle sampling the distances\n",
    "\n",
    "    TODO: we can make this even faster by: \n",
    "    - not including distances in the first sources call (setting all to 1)\n",
    "    - integrating\n",
    "    - filtering based on hz and whether they merged\n",
    "    - then assign distances to subset\n",
    "    - then do sources with those\n",
    "    - filter on SNR\n",
    "    - combine filters\n",
    "    \"\"\"\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    ######\n",
    "    # unpack data\n",
    "    start_unpack = time.time()\n",
    "    \n",
    "    # These allow linking back to the data of the systems    \n",
    "    system_indices = convolution_results[\"sampled_indices\"] \n",
    "    local_indices = np.arange(len(system_indices))\n",
    "    stop_unpack = time.time()\n",
    "\n",
    "    ######\n",
    "    # Set formation and event lookback times\n",
    "    formation_lookback_times = np.random.random(system_indices.shape) * time_bin_info_dict['bin_size'] + time_bin_info_dict['bin_edge_lower']\n",
    "    event_lookback_times = formation_lookback_times - data_dict['delay_time'][system_indices]\n",
    "\n",
    "\n",
    "    print(time_bin_info_dict)\n",
    "    print(event_lookback_times)\n",
    "    \n",
    "    # Filter out systems that occur in the future \n",
    "    # TODO: make function\n",
    "    future_mask = event_lookback_times > 0\n",
    "    number_of_future_events = future_mask.size-future_mask.sum()\n",
    "\n",
    "    system_indices = system_indices[future_mask==1]\n",
    "    local_indices = local_indices[future_mask==1]\n",
    "    \n",
    "    convolution_results = select_dict_entries_with_new_indices(\n",
    "        sampled_data_dict=convolution_results,\n",
    "        new_indices=local_indices,\n",
    "    )\n",
    "    \n",
    "    config[\"logger\"].warning(\n",
    "        f'filtered out {number_of_future_events} future events'\n",
    "    )\n",
    "\n",
    "    ######\n",
    "    # select system properties using the indices\n",
    "    start_readout = time.time()\n",
    "    sma = data_dict[\"semimajor_axis\"][system_indices] * u.Rsun\n",
    "    m_1 = data_dict[\"mass1\"][system_indices] * u.Msun\n",
    "    m_2 = data_dict[\"mass2\"][system_indices] * u.Msun \n",
    "    eccentricity = data_dict[\"eccentricity\"][system_indices]\n",
    "    periods = get_period(sma, m_1, m_2)\n",
    "    f_orb_i = (1 / periods).to(u.Hz)\n",
    "    dummy_dist = np.ones(sma.shape) * u.kpc # Provide fake distances at first because we will filter out any system that is not in the correct frequency band\n",
    "    stop_readout = time.time()\n",
    "\n",
    "    #########\n",
    "    # Evolve systems under GW radiation \n",
    "    start_GW = time.time()\n",
    "\n",
    "    # Set up sources In Legwork\n",
    "    # TODO: make function\n",
    "    sources = lw.source.Source(\n",
    "        m_1=m_1,\n",
    "        m_2=m_2,\n",
    "        ecc=eccentricity,\n",
    "        f_orb=f_orb_i,\n",
    "        dist=dummy_dist,\n",
    "        interpolate_g=True,\n",
    "    )\n",
    "\n",
    "    # Evolve the systems until today\n",
    "    t_evol = event_lookback_times\n",
    "    sources.evolve_sources(t_evol)\n",
    "    f_orb_now = sources.f_orb # Get the orbital frequencies of the systems at current-day.\n",
    "    convolution_results[\"f_orb_now\"] = f_orb_now # Store the orbital frequency in the result dict\n",
    "\n",
    "    stop_GW = time.time()\n",
    "\n",
    "    #####################################################\n",
    "    # \n",
    "    \n",
    "    ####\n",
    "    # Make categorisations and filter out systems\n",
    "    start_mask = time.time()\n",
    "\n",
    "    ##############\n",
    "    # determine (un)merged systems \n",
    "    # TODO: make function\n",
    "\n",
    "    # Whether a system is merged is determined by checking if its orbital frequency is above 100hz\n",
    "    merged_frequency = 1e2 * u.Hz\n",
    "\n",
    "    unmerged_mask = f_orb_now < merged_frequency\n",
    "\n",
    "    config[\"logger\"].warning(\n",
    "        f\"Of the total of {len(local_indices)} systems {np.count_nonzero(unmerged_mask==0)} are merged by today and {np.count_nonzero(unmerged_mask)} are not\"\n",
    "    )\n",
    "\n",
    "    ##############\n",
    "    # determine unmerged systems in LISA passband\n",
    "    # TODO: make function\n",
    "    lower_bound_LISA_passband = 1e-5 * u.Hz\n",
    "    upper_bound_LISA_passband = 1e-1 * u.Hz\n",
    "    \n",
    "    waveband_mask = (f_orb_now >= lower_bound_LISA_passband) & (f_orb_now <= upper_bound_LISA_passband)\n",
    "\n",
    "    config[\"logger\"].warning(\n",
    "        f\"Of the total of {len(local_indices)} systems {np.count_nonzero(waveband_mask)} are within the lisa frequency passband ([{lower_bound_LISA_passband},{upper_bound_LISA_passband}])\"\n",
    "    )\n",
    "\n",
    "    ##############\n",
    "    # combine masks and filter\n",
    "    combined_mask = unmerged_mask * waveband_mask\n",
    "    \n",
    "    local_indices_unmerged_systems_in_waveband = local_indices[combined_mask==1]\n",
    "    system_indices_unmerged_systems_in_waveband = system_indices[combined_mask==1]\n",
    "    \n",
    "    config[\"logger\"].warning(\n",
    "        f\"Of the total of {len(local_indices)} systems {np.count_nonzero(combined_mask)} are within the lisa frequency passband ([{lower_bound_LISA_passband},{upper_bound_LISA_passband}]) and are not merged\"\n",
    "    )\n",
    "\n",
    "    #####################################################\n",
    "    # sample distances\n",
    "    start_dist = time.time()\n",
    "    dist = sample_distances_interpolated(NBin=len(local_indices_unmerged_systems_in_waveband), Hr=Hr, inverse_cdf=inverse_cdf)\n",
    "    stop_dist = time.time()\n",
    "\n",
    "    #######\n",
    "    # filter based on detectability here\n",
    "    sources = lw.source.Source(\n",
    "        m_1=m_1[local_indices_unmerged_systems_in_waveband],\n",
    "        m_2=m_2[local_indices_unmerged_systems_in_waveband],\n",
    "        ecc=eccentricity[local_indices_unmerged_systems_in_waveband],\n",
    "        f_orb=f_orb_now[local_indices_unmerged_systems_in_waveband],\n",
    "        dist=dist,\n",
    "        interpolate_g=True,\n",
    "    )\n",
    "    \n",
    "    snr = sources.get_snr(verbose=False)\n",
    "    detectability_mask = snr > 7\n",
    "\n",
    "    #############\n",
    "    # filter out undetectable systems\n",
    "    local_indices_detectable_unmerged_systems_in_waveband = local_indices_unmerged_systems_in_waveband[detectability_mask==1]\n",
    "    system_indices_detectable_unmerged_systems_in_waveband = system_indices_unmerged_systems_in_waveband[detectability_mask==1]\n",
    "\n",
    "    config[\"logger\"].critical(\n",
    "        f\"time-bin {time_bin_info_dict['bin_number']}: Of the total of {len(local_indices_unmerged_systems_in_waveband)} unmerged systems in the lisa waveband {np.count_nonzero(detectability_mask)} have a signal to noise (SNR) ratio of above 7 in an observation period of 4 years\"\n",
    "    )\n",
    "\n",
    "    ##############\n",
    "    # combine masks and construct filtered index list\n",
    "    stop_mask = time.time()\n",
    "    stop = time.time()\n",
    "\n",
    "    config[\"logger\"].critical(\n",
    "        \"The post-convolution step took {}s, {}s of which for unpacking. {}s is for readout. {}s is for distance sampling. {}s of which for GW integration, and {}s of which for masking.\".format(\n",
    "            stop-start,\n",
    "            stop_unpack-start_unpack,\n",
    "            stop_readout-start_readout,\n",
    "            stop_dist-start_dist,\n",
    "            stop_GW-start_GW,\n",
    "            stop_mask-start_mask            \n",
    "        )\n",
    "    )\n",
    "\n",
    "    #######\n",
    "    # return only data from now unmerged systems within the lisa passband\n",
    "    # We use the function `select_dict_entries_with_new_indices` to select the data using the new indices in every entry in the dict. \n",
    "    # Result dict does not contain that many \n",
    "    convolution_results = select_dict_entries_with_new_indices(\n",
    "        sampled_data_dict=convolution_results,\n",
    "        new_indices=local_indices_detectable_unmerged_systems_in_waveband,\n",
    "    )\n",
    "\n",
    "    convolution_results['dist'] = dist[snr>7]\n",
    "    convolution_results['snr'] = snr[snr>7]\n",
    "\n",
    "    return convolution_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72339dce-59a7-48b3-86ef-3e433dbd41d5",
   "metadata": {},
   "source": [
    "Lastly, we set up the `convolution_config`, which binds everything together. Most of this is similar to other scripts, but here we use a different kind of convolution, namely convolution by sampling. Information about this type of sampling is available **here TODO: link**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c03c2637-b7c8-480f-b548-e55a3119ed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "#\n",
    "\n",
    "# create file\n",
    "output_hdf5_filename = os.path.join(TMP_DIR, \"output_hdf5.h5\")\n",
    "generate_boilerplate_outputfile(output_hdf5_filename)\n",
    "\n",
    "# store the data frame in the hdf5file\n",
    "wd_binaries.to_hdf(output_hdf5_filename, key=\"input_data/example_usecase_UCB_events\")\n",
    "\n",
    "#\n",
    "convolution_config = copy.copy(default_convolution_config)\n",
    "convolution_config[\"output_filename\"] = output_hdf5_filename\n",
    "convolution_config[\"tmp_dir\"] = TMP_DIR\n",
    "convolution_config['num_cores'] = 1 # change this for any production-run\n",
    "convolution_config['logger'].setLevel(logging.INFO)\n",
    "\n",
    "###\n",
    "# convolution instructions\n",
    "convolution_config[\"convolution_instructions\"] = [\n",
    "    {\n",
    "        **default_convolution_instruction,\n",
    "        \"convolution_type\": \"sample\",\n",
    "        \"input_data_name\": \"example_usecase_UCB_events\",\n",
    "        \"output_data_name\": \"example_usecase_UCB_events\",\n",
    "        \"post_convolution_function\": post_convolution_function,\n",
    "        \"data_column_dict\": {\n",
    "            # required\n",
    "            \"normalized_yield\": \"normalized_yield\",\n",
    "            \"delay_time\": {\"column_name\": \"time\", \"unit\": u.Myr},\n",
    "            # The columns below are required because we use them in the post_convolution function. We can either give their units here, or we can assign them in the post-convolution function.\n",
    "            \"semimajor_axis\": \"semiMajor\",\n",
    "            \"mass1\": \"mass1\",\n",
    "            \"mass2\": \"mass2\",\n",
    "            \"eccentricity\": \"eccentricity\"\n",
    "        },\n",
    "        'multiply_by_sfr_time_binsize': True\n",
    "    },\n",
    "]\n",
    "\n",
    "convolution_config['convolution_lookback_time_bin_edges'] = np.arange(0, 12, 0.25)*u.Gyr\n",
    "convolution_config['multiprocessing']=False\n",
    "\n",
    "# store SFR dict\n",
    "convolution_config[\"SFR_info\"] = sfr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44666ff5-827b-4d6f-baed-910a9e762d1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[convolution_by_sampling.py:127 -       sample_systems ] 2025-04-14 23:41:39,837: Sampling systems. Using yield array [  0.           0.           0.         ... 134.03195135 134.03195135\n",
      " 134.03195135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting convolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[convolution_by_sampling.py:169 -       sample_systems ] 2025-04-14 23:41:40,657: Sampled (12282219,) systems.\n",
      "[convolution_by_sampling.py:77 - convolution_by_sampling_post_convolution_hook_wrapper ] 2025-04-14 23:41:40,658: Handling post-convolution function hook call for convolution by sampling\n",
      "[2101976194.py:67 - post_convolution_function ] 2025-04-14 23:41:40,899: filtered out 11378381 future events\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bin_number': 0, 'bin_center': <Quantity 0.125 Gyr>, 'bin_edge_lower': <Quantity 0. Gyr>, 'bin_size': <Quantity 0.25 Gyr>, 'bin_type': 'convolution time', 'time_type': 'lookback_time', 'reverse_bin_order': False, 'convolution_direction': 'backward'}\n",
      "[-9.69849756 -9.60858267 -9.7141721  ... -0.04516695  0.1469323\n",
      "  0.06781169] Gyr\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (12282219,) (903838,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# convolve\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarting convolution\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mconvolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvolution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinished convolution\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/projects/binary_c_root/syntheticstellarpopconvolve/syntheticstellarpopconvolve/convolve.py:45\u001b[0m, in \u001b[0;36mconvolve\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     41\u001b[0m config \u001b[38;5;241m=\u001b[39m prepare_redshift_interpolator(config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m##############################################\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Convolution phase\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[43mconvolve_populations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m##############################################\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Cleanup phase\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# TODO: implement cleanup\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     52\u001b[0m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogger\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvolution finished\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/projects/binary_c_root/syntheticstellarpopconvolve/syntheticstellarpopconvolve/convolve_populations.py:787\u001b[0m, in \u001b[0;36mconvolve_populations\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    783\u001b[0m         bound_handle_convolution_steps(\n\u001b[1;32m    784\u001b[0m             convolution_instruction\u001b[38;5;241m=\u001b[39mconvolution_instruction\n\u001b[1;32m    785\u001b[0m         )\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 787\u001b[0m     \u001b[43mbound_handle_convolution_steps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvolution_instruction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvolution_instruction\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/binary_c_root/syntheticstellarpopconvolve/syntheticstellarpopconvolve/convolve_populations.py:726\u001b[0m, in \u001b[0;36mhandle_convolution_steps\u001b[0;34m(config, convolution_instruction, sfr_dict)\u001b[0m\n\u001b[1;32m    719\u001b[0m pre_convolution(\n\u001b[1;32m    720\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    721\u001b[0m     convolution_instruction\u001b[38;5;241m=\u001b[39mconvolution_instruction,\n\u001b[1;32m    722\u001b[0m     sfr_dict\u001b[38;5;241m=\u001b[39msfr_dict,\n\u001b[1;32m    723\u001b[0m )\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# actual convolution\u001b[39;00m\n\u001b[0;32m--> 726\u001b[0m \u001b[43mhandle_sequential_or_multiprocessing_convolution\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvolution_instruction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvolution_instruction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43msfr_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msfr_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    733\u001b[0m post_convolution(\n\u001b[1;32m    734\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    735\u001b[0m     convolution_instruction\u001b[38;5;241m=\u001b[39mconvolution_instruction,\n\u001b[1;32m    736\u001b[0m     sfr_dict\u001b[38;5;241m=\u001b[39msfr_dict,\n\u001b[1;32m    737\u001b[0m )\n",
      "File \u001b[0;32m~/projects/binary_c_root/syntheticstellarpopconvolve/syntheticstellarpopconvolve/convolve_populations.py:706\u001b[0m, in \u001b[0;36mhandle_sequential_or_multiprocessing_convolution\u001b[0;34m(config, convolution_instruction, sfr_dict)\u001b[0m\n\u001b[1;32m    700\u001b[0m     handle_multiprocessing_convolution(\n\u001b[1;32m    701\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    702\u001b[0m         convolution_instruction\u001b[38;5;241m=\u001b[39mconvolution_instruction,\n\u001b[1;32m    703\u001b[0m         sfr_dict\u001b[38;5;241m=\u001b[39msfr_dict,\n\u001b[1;32m    704\u001b[0m     )\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m     \u001b[43mhandle_sequential_convolution\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvolution_instruction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvolution_instruction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m        \u001b[49m\u001b[43msfr_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msfr_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/binary_c_root/syntheticstellarpopconvolve/syntheticstellarpopconvolve/convolve_populations.py:639\u001b[0m, in \u001b[0;36mhandle_sequential_convolution\u001b[0;34m(config, convolution_instruction, sfr_dict)\u001b[0m\n\u001b[1;32m    628\u001b[0m job_dict \u001b[38;5;241m=\u001b[39m create_job_dict(\n\u001b[1;32m    629\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    630\u001b[0m     sfr_dict\u001b[38;5;241m=\u001b[39msfr_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    634\u001b[0m     bin_number\u001b[38;5;241m=\u001b[39mbin_number,\n\u001b[1;32m    635\u001b[0m )\n\u001b[1;32m    637\u001b[0m \u001b[38;5;66;03m# #############\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;66;03m# run convolution\u001b[39;00m\n\u001b[0;32m--> 639\u001b[0m convolution_results \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_convolution_choice\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43msfr_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msfr_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvolution_instruction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvolution_instruction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#\u001b[39;49;00m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersistent_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersistent_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprevious_convolution_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprevious_convolution_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;66;03m# Store previous results\u001b[39;00m\n\u001b[1;32m    651\u001b[0m previous_convolution_results \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(convolution_results)\n",
      "File \u001b[0;32m~/projects/binary_c_root/syntheticstellarpopconvolve/syntheticstellarpopconvolve/convolve_populations.py:296\u001b[0m, in \u001b[0;36mhandle_convolution_choice\u001b[0;34m(config, job_dict, sfr_dict, convolution_instruction, data_dict, persistent_data, previous_convolution_results)\u001b[0m\n\u001b[1;32m    286\u001b[0m     convolution_results \u001b[38;5;241m=\u001b[39m convolve_on_the_fly(\n\u001b[1;32m    287\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    288\u001b[0m         sfr_dict\u001b[38;5;241m=\u001b[39msfr_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    293\u001b[0m         previous_convolution_results\u001b[38;5;241m=\u001b[39mprevious_convolution_results,\n\u001b[1;32m    294\u001b[0m     )\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 296\u001b[0m     convolution_results \u001b[38;5;241m=\u001b[39m \u001b[43mconvolve_pre_calculated_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43msfr_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msfr_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_bin_info_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_bin_info_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvolution_instruction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvolution_instruction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#\u001b[39;49;00m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersistent_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersistent_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprevious_convolution_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprevious_convolution_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m convolution_results\n",
      "File \u001b[0;32m~/projects/binary_c_root/syntheticstellarpopconvolve/syntheticstellarpopconvolve/convolve_pre_calculated_data.py:120\u001b[0m, in \u001b[0;36mconvolve_pre_calculated_data\u001b[0;34m(config, sfr_dict, data_dict, time_bin_info_dict, convolution_instruction, persistent_data, previous_convolution_results)\u001b[0m\n\u001b[1;32m    111\u001b[0m     convolution_results \u001b[38;5;241m=\u001b[39m sample_systems(\n\u001b[1;32m    112\u001b[0m         yield_array\u001b[38;5;241m=\u001b[39myield_array,\n\u001b[1;32m    113\u001b[0m         lookback_time_bin_size\u001b[38;5;241m=\u001b[39mtime_bin_info_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbin_size\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    117\u001b[0m     )\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# handle postconvolution\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m     convolution_results \u001b[38;5;241m=\u001b[39m \u001b[43mconvolution_by_sampling_post_convolution_hook_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43msfr_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msfr_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_bin_info_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_bin_info_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvolution_instruction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvolution_instruction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvolution_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvolution_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#\u001b[39;49;00m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersistent_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersistent_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprevious_convolution_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprevious_convolution_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# handle postconvolution\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     convolution_results \u001b[38;5;241m=\u001b[39m convolution_by_integration_post_convolution_hook_wrapper(\n\u001b[1;32m    135\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    136\u001b[0m         sfr_dict\u001b[38;5;241m=\u001b[39msfr_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    143\u001b[0m         previous_convolution_results\u001b[38;5;241m=\u001b[39mprevious_convolution_results,\n\u001b[1;32m    144\u001b[0m     )\n",
      "File \u001b[0;32m~/projects/binary_c_root/syntheticstellarpopconvolve/syntheticstellarpopconvolve/convolution_by_sampling.py:83\u001b[0m, in \u001b[0;36mconvolution_by_sampling_post_convolution_hook_wrapper\u001b[0;34m(config, sfr_dict, data_dict, time_bin_info_dict, convolution_instruction, convolution_results, persistent_data, previous_convolution_results)\u001b[0m\n\u001b[1;32m     77\u001b[0m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogger\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHandling post-convolution function hook call for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name)\n\u001b[1;32m     79\u001b[0m )\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m#############\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# call hook\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m convolution_results \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_post_convolution_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43msfr_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msfr_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_bin_info_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_bin_info_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvolution_instruction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvolution_instruction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvolution_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvolution_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#\u001b[39;49;00m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersistent_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersistent_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprevious_convolution_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprevious_convolution_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m convolution_results\n",
      "File \u001b[0;32m~/projects/binary_c_root/syntheticstellarpopconvolve/syntheticstellarpopconvolve/post_convolution_hook_routines.py:113\u001b[0m, in \u001b[0;36mhandle_post_convolution_function\u001b[0;34m(config, sfr_dict, data_dict, time_bin_info_dict, convolution_instruction, convolution_results, name, persistent_data, previous_convolution_results)\u001b[0m\n\u001b[1;32m    104\u001b[0m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogger\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHandling \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m post-convolution function call using function \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and arguments \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    106\u001b[0m         name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m     )\n\u001b[1;32m    110\u001b[0m )\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Call post-convolution function\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m convolution_results \u001b[38;5;241m=\u001b[39m \u001b[43mpost_convolution_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpost_convolution_function_args\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m################\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# Check shape/type of results\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# check if the result is a list\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(convolution_results, \u001b[38;5;28mlist\u001b[39m):\n",
      "Cell \u001b[0;32mIn[11], line 100\u001b[0m, in \u001b[0;36mpost_convolution_function\u001b[0;34m(config, sfr_dict, data_dict, time_bin_info_dict, convolution_results, convolution_instruction)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Evolve the systems until today\u001b[39;00m\n\u001b[1;32m     99\u001b[0m t_evol \u001b[38;5;241m=\u001b[39m event_lookback_times\n\u001b[0;32m--> 100\u001b[0m \u001b[43msources\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevolve_sources\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_evol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m f_orb_now \u001b[38;5;241m=\u001b[39m sources\u001b[38;5;241m.\u001b[39mf_orb \u001b[38;5;66;03m# Get the orbital frequencies of the systems at current-day.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m convolution_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf_orb_now\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m f_orb_now \u001b[38;5;66;03m# Store the orbital frequency in the result dict\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.21/envs/binarycpython3.9.21/lib/python3.9/site-packages/legwork/source.py:1008\u001b[0m, in \u001b[0;36mSource.evolve_sources\u001b[0;34m(self, t_evol, create_new_class)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_merge \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1006\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_merger_time()\n\u001b[0;32m-> 1008\u001b[0m merged \u001b[38;5;241m=\u001b[39m \u001b[43mt_evol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt_merge\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# separate out the exactly circular sources from eccentric ones\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m c_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlogical_and(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mecc \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m, np\u001b[38;5;241m.\u001b[39mlogical_not(merged))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.21/envs/binarycpython3.9.21/lib/python3.9/site-packages/astropy/units/quantity.py:696\u001b[0m, in \u001b[0;36mQuantity.__array_ufunc__\u001b[0;34m(self, function, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 696\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.21/envs/binarycpython3.9.21/lib/python3.9/site-packages/astropy/units/quantity.py:671\u001b[0m, in \u001b[0;36mQuantity.__array_ufunc__\u001b[0;34m(self, function, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m     arrays\u001b[38;5;241m.\u001b[39mappend(converter(input_) \u001b[38;5;28;01mif\u001b[39;00m converter \u001b[38;5;28;01melse\u001b[39;00m input_)\n\u001b[1;32m    670\u001b[0m \u001b[38;5;66;03m# Call our superclass's __array_ufunc__\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__array_ufunc__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;66;03m# If unit is None, a plain array is expected (e.g., comparisons), which\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;66;03m# means we're done.\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;66;03m# We're also done if the result was None (for method 'at') or\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;66;03m# NotImplemented, which can happen if other inputs/outputs override\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;66;03m# __array_ufunc__; hopefully, they can then deal with us.\u001b[39;00m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (12282219,) (903838,) "
     ]
    }
   ],
   "source": [
    "# convolve\n",
    "print(\"starting convolution\")\n",
    "convolve(config=convolution_config)\n",
    "\n",
    "print(\"finished convolution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ad7176-fbbf-4f33-89fd-73abae739376",
   "metadata": {},
   "source": [
    "Now that the convolution is finished, we can read out the results. Remember, in this case, the bins in which the data is stored indicate the range of lookback times in which the systems are born. They are all evolved to the current day, however, so we need to add the results of all these bins together to get a complete view of the population of dwd systems that will be observable by LISA at current times!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f998e083-4e6b-4a04-84dc-e41db8388325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import legwork.strain as strain\n",
    "\n",
    "total_forb_array = np.array([])\n",
    "total_ecc_array = np.array([])\n",
    "total_m1_array = np.array([])\n",
    "total_m2_array = np.array([])\n",
    "total_dist_array = np.array([])\n",
    "\n",
    "\n",
    "# \n",
    "df = pd.read_hdf(output_hdf5_filename, key=\"input_data/example_usecase_UCB_events\")\n",
    "print(df)\n",
    "\n",
    "# read out content and integrate until today\n",
    "with h5py.File(convolution_config[\"output_filename\"], \"r\") as output_hdf5_file:\n",
    "    group_key = \"output_data/example_usecase_UCB_events/example_usecase_UCB_events/convolution_results\"\n",
    "    \n",
    "    formation_time_bin_keys = list(\n",
    "        output_hdf5_file[group_key].keys()\n",
    "    )\n",
    "\n",
    "    ################\n",
    "    #\n",
    "\n",
    "    # loop over the formation-time bins\n",
    "    formation_time_bin_keys = sorted(\n",
    "        formation_time_bin_keys, key=lambda x: float(x.split(\" \")[0])\n",
    "    )\n",
    "    for formation_time_bin_key in formation_time_bin_keys:\n",
    "        # \n",
    "        time_bin_group_key = f\"{group_key}/{formation_time_bin_key}\"\n",
    "            \n",
    "        # print(\"=================================\")\n",
    "        # print(f\"formation_time_bin_key: {formation_time_bin_key}\")\n",
    "        # print(\"=================================\")\n",
    "        \n",
    "        #####\n",
    "        # convert units\n",
    "        unit_dict = json.loads(\n",
    "            output_hdf5_file[\n",
    "                f\"{group_key}/{formation_time_bin_key}\"\n",
    "            ].attrs[\"units\"]\n",
    "        )\n",
    "        unit_dict = {key: u.Unit(val) for key, val in unit_dict.items()}\n",
    "\n",
    "        ###########\n",
    "        # Read out data\n",
    "        sampled_indices = output_hdf5_file[f'{time_bin_group_key}/sampled_indices'][()]\n",
    "        dist = output_hdf5_file[f'{time_bin_group_key}/dist'][()] * u.kpc\n",
    "        f_orb_now = output_hdf5_file[f'{time_bin_group_key}/f_orb_now'][()] * unit_dict['f_orb_now']\n",
    "\n",
    "        # select with indices\n",
    "        eccentricity = df.iloc[sampled_indices]['eccentricity'].to_numpy()\n",
    "        mass1 = df.iloc[sampled_indices]['mass1'].to_numpy() * u.Msun\n",
    "        mass2 = df.iloc[sampled_indices]['mass2'].to_numpy() * u.Msun\n",
    "\n",
    "        # add to combined arrays\n",
    "        total_forb_array = np.concatenate([total_forb_array, f_orb_now])\n",
    "        total_ecc_array = np.concatenate([total_ecc_array, eccentricity])\n",
    "        total_m1_array = np.concatenate([total_m1_array, mass1])\n",
    "        total_m2_array = np.concatenate([total_m2_array, mass2])\n",
    "        total_dist_array = np.concatenate([total_dist_array, dist])\n",
    "\n",
    "print(\"Found a total number of {} detectable systems\".format(len(total_forb_array)))\n",
    "\n",
    "#######\n",
    "# Set up the sources again\n",
    "sources = lw.source.Source(\n",
    "    m_1=total_m1_array,\n",
    "    m_2=total_m2_array,\n",
    "    ecc=total_ecc_array,\n",
    "    f_orb=total_forb_array,\n",
    "    dist=total_dist_array,\n",
    "    interpolate_g=True,\n",
    ")                                      \n",
    "snr = sources.get_snr(verbose=True)\n",
    "print(len(snr[snr>7]))\n",
    "fig, ax = sources.plot_source_variables(xstr=\"f_orb\", ystr=\"snr\", disttype=\"kde\", log_scale=(True, True))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fd7d5c-5d8a-41f9-ba3f-2cf7ae0782ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "import legwork as lw\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Define your source parameters\n",
    "# -----------------------------\n",
    "# For a double white-dwarf binary:\n",
    "m_1 = 0.3 * u.Msun   # mass of the first WD\n",
    "m_2 = 0.3 * u.Msun   # mass of the second WD\n",
    "eccentricity = 0\n",
    "\n",
    "# Orbital frequency (f_orb): frequency of the binary's orbit\n",
    "# Note that the gravitational wave frequency for a circular orbit is 2*f_orb\n",
    "f_orb = 1.0e-3 * u.Hz\n",
    "\n",
    "# Distance to the source\n",
    "dist = 1000.0 * u.pc\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Create a Source object\n",
    "# -----------------------------\n",
    "# The Source class in LEGWORK can take arrays or scalars of parameters. \n",
    "# Here we demonstrate with single (scalar) values.\n",
    "binary = lw.source.Source(\n",
    "    m_1=m_1,\n",
    "    m_2=m_2,\n",
    "    ecc=eccentricity,\n",
    "    f_orb=f_orb,\n",
    "    dist=dist,\n",
    "    # interpolate_g=len(local_indices) > 1000,\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Compute the SNR\n",
    "# -----------------------------\n",
    "# By default, LEGWORK uses the standard LISA sensitivity PSD from Robson et al. (2019).\n",
    "snr = binary.get_snr()\n",
    "print(snr)\n",
    "# print(f\"SNR = {snr:.3f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Compute the detection probability\n",
    "# -----------------------------\n",
    "# LEGWORK uses a characteristic SNR threshold approach by default \n",
    "# (commonly ~7 for a \"resolvable\" detection in many LISA studies).\n",
    "# You can override the default threshold via the \"snr_thresh\" argument if desired.\n",
    "# p_det = binary.get_detection_probability()\n",
    "# print(p_det)\n",
    "# print(p_det\n",
    "# # p_det = binary.get_detection_probability()\n",
    "\n",
    "\n",
    "# Check if the binary is detectable above SNR=7\n",
    "is_detectable = binary.detectable(snr_threshold=7.0)\n",
    "print(is_detectable)  # returns True or False\n",
    "      \n",
    "# print(f\"Detection probability = {p_det:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4d5c3b-f4c1-4200-b16d-7cc6effc24f7",
   "metadata": {},
   "source": [
    "## Advanced steps\n",
    "This example is a good step towards a solid predictive calculation for the population of observable white dwarf systems for the LISA mission, but it does lack some sophistication. In particular, the star formation history information is not so realistic. \n",
    "\n",
    "This example can be made more sophisticated by e.g.:\n",
    "- Using a spatially-defined star-formation rate history. One can provide a list of starformation histories to the code, each element then representing a part of the grid where the SFR is defined in.\n",
    "- Splitting off systems that may undergo RLOF\n",
    "- providing on-sky angle (dec, asc), inclination of system relative to us, orbital phase for eccentric systems\n",
    "\n",
    "https://legwork.readthedocs.io/en/latest/notebooks/Source.html#Position-inclination-polarisation-specfic-sources\n",
    "\n",
    "TODO: determine which systems that are (at present day) in the lisa frequency range should have interacted through RLOF\n",
    "TODO: of the systems that are not RLOFing and are within the lisa waveband, store: indices, source.f_orb_now. the rest can be retrieved elsewhere\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
